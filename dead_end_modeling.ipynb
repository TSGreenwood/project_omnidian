{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random dead ends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on features from Omnidian database 101, we compare K-Nearest Neighbors, Gradient Boosting, Random Forest, Bagging, and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/humanperson/anaconda3/envs/learn2env/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to self: handle those duplicates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Asset_Id</th>\n",
       "      <th>Root_Cause</th>\n",
       "      <th>Ticket_Creation_Reason</th>\n",
       "      <th>asset_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>tilt</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>Ticket_Origin</th>\n",
       "      <th>Date_Ticket_Initially_Assigned</th>\n",
       "      <th>Date_Ticket_Closed</th>\n",
       "      <th>installed_by</th>\n",
       "      <th>installation_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23947</th>\n",
       "      <td>101112604</td>\n",
       "      <td>root_cause_normal_wear_and_tear</td>\n",
       "      <td>communication offline</td>\n",
       "      <td>Residential Solar PV</td>\n",
       "      <td>38.944642</td>\n",
       "      <td>-121.248833</td>\n",
       "      <td>37.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>origin_omnidian_customer</td>\n",
       "      <td>2018-10-22 17:25:27</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>Williams Lifetime Builders Inc. DBA Lifetime S...</td>\n",
       "      <td>2013-04-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23947</th>\n",
       "      <td>101112604</td>\n",
       "      <td>root_cause_normal_wear_and_tear</td>\n",
       "      <td>communication offline</td>\n",
       "      <td>Residential Solar PV</td>\n",
       "      <td>38.944642</td>\n",
       "      <td>-121.248833</td>\n",
       "      <td>37.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>origin_omnidian_customer</td>\n",
       "      <td>2018-10-22 17:25:27</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>Williams Lifetime Builders Inc. DBA Lifetime S...</td>\n",
       "      <td>2013-04-04 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27384</th>\n",
       "      <td>101113056</td>\n",
       "      <td>root_cause_normal_wear_and_tear</td>\n",
       "      <td>system inspection</td>\n",
       "      <td>Residential Solar PV</td>\n",
       "      <td>34.101697</td>\n",
       "      <td>-118.146646</td>\n",
       "      <td>18.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>origin_homeowner</td>\n",
       "      <td>2018-12-20 06:49:02</td>\n",
       "      <td>2019-02-09</td>\n",
       "      <td>Green Tech Solutions Inc.</td>\n",
       "      <td>2014-04-08 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27384</th>\n",
       "      <td>101113056</td>\n",
       "      <td>root_cause_normal_wear_and_tear</td>\n",
       "      <td>system inspection</td>\n",
       "      <td>Residential Solar PV</td>\n",
       "      <td>34.101697</td>\n",
       "      <td>-118.146646</td>\n",
       "      <td>18.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>origin_homeowner</td>\n",
       "      <td>2018-12-20 06:49:02</td>\n",
       "      <td>2019-02-09</td>\n",
       "      <td>Green Tech Solutions Inc.</td>\n",
       "      <td>2014-04-08 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27384</th>\n",
       "      <td>101113056</td>\n",
       "      <td>root_cause_normal_wear_and_tear</td>\n",
       "      <td>system inspection</td>\n",
       "      <td>Residential Solar PV</td>\n",
       "      <td>34.101697</td>\n",
       "      <td>-118.146646</td>\n",
       "      <td>18.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>origin_homeowner</td>\n",
       "      <td>2018-12-20 06:49:02</td>\n",
       "      <td>2019-02-09</td>\n",
       "      <td>Green Tech Solutions Inc.</td>\n",
       "      <td>2014-04-08 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Asset_Id                       Root_Cause Ticket_Creation_Reason  \\\n",
       "Ticket_Id                                                                      \n",
       "23947      101112604  root_cause_normal_wear_and_tear  communication offline   \n",
       "23947      101112604  root_cause_normal_wear_and_tear  communication offline   \n",
       "27384      101113056  root_cause_normal_wear_and_tear      system inspection   \n",
       "27384      101113056  root_cause_normal_wear_and_tear      system inspection   \n",
       "27384      101113056  root_cause_normal_wear_and_tear      system inspection   \n",
       "\n",
       "                     asset_type   latitude   longitude  tilt  azimuth  \\\n",
       "Ticket_Id                                                               \n",
       "23947      Residential Solar PV  38.944642 -121.248833  37.0    190.0   \n",
       "23947      Residential Solar PV  38.944642 -121.248833  37.0    190.0   \n",
       "27384      Residential Solar PV  34.101697 -118.146646  18.0    180.0   \n",
       "27384      Residential Solar PV  34.101697 -118.146646  18.0    180.0   \n",
       "27384      Residential Solar PV  34.101697 -118.146646  18.0     90.0   \n",
       "\n",
       "                      Ticket_Origin Date_Ticket_Initially_Assigned  \\\n",
       "Ticket_Id                                                            \n",
       "23947      origin_omnidian_customer            2018-10-22 17:25:27   \n",
       "23947      origin_omnidian_customer            2018-10-22 17:25:27   \n",
       "27384              origin_homeowner            2018-12-20 06:49:02   \n",
       "27384              origin_homeowner            2018-12-20 06:49:02   \n",
       "27384              origin_homeowner            2018-12-20 06:49:02   \n",
       "\n",
       "          Date_Ticket_Closed  \\\n",
       "Ticket_Id                      \n",
       "23947             2018-11-29   \n",
       "23947             2018-11-29   \n",
       "27384             2019-02-09   \n",
       "27384             2019-02-09   \n",
       "27384             2019-02-09   \n",
       "\n",
       "                                                installed_by  \\\n",
       "Ticket_Id                                                      \n",
       "23947      Williams Lifetime Builders Inc. DBA Lifetime S...   \n",
       "23947      Williams Lifetime Builders Inc. DBA Lifetime S...   \n",
       "27384                              Green Tech Solutions Inc.   \n",
       "27384                              Green Tech Solutions Inc.   \n",
       "27384                              Green Tech Solutions Inc.   \n",
       "\n",
       "             installation_date  \n",
       "Ticket_Id                       \n",
       "23947      2013-04-04 00:00:00  \n",
       "23947      2013-04-04 00:00:00  \n",
       "27384      2014-04-08 00:00:00  \n",
       "27384      2014-04-08 00:00:00  \n",
       "27384      2014-04-08 00:00:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data101 = pd.read_csv('data/eda101.csv', index_col='Ticket_Id')\n",
    "data101.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 825 entries, 23947 to 32514\n",
      "Data columns (total 13 columns):\n",
      "Asset_Id                          825 non-null int64\n",
      "Root_Cause                        825 non-null object\n",
      "Ticket_Creation_Reason            825 non-null object\n",
      "asset_type                        825 non-null object\n",
      "latitude                          825 non-null float64\n",
      "longitude                         825 non-null float64\n",
      "tilt                              825 non-null float64\n",
      "azimuth                           825 non-null float64\n",
      "Ticket_Origin                     825 non-null object\n",
      "Date_Ticket_Initially_Assigned    825 non-null object\n",
      "Date_Ticket_Closed                825 non-null object\n",
      "installed_by                      825 non-null object\n",
      "installation_date                 825 non-null object\n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 90.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data101.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign target to Root_Cause and Train-Test-Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider stratifying when train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data101.drop('Root_Cause', axis=1).copy()\n",
    "y = data101['Root_Cause']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding: since our data is largely categorical but our models require numeric inputs, we one hot encode it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = ['Asset_Id', 'Ticket_Creation_Reason', 'asset_type', \n",
    "                'Ticket_Origin', 'installed_by']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Asset_Id', 'Root_Cause', 'Ticket_Creation_Reason', 'asset_type',\n",
       "       'latitude', 'longitude', 'tilt', 'azimuth', 'Ticket_Origin',\n",
       "       'Date_Ticket_Initially_Assigned', 'Date_Ticket_Closed', 'installed_by',\n",
       "       'installation_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data101.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/humanperson/anaconda3/envs/learn2env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "arrays used as indices must be of integer (or boolean) type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7c3b5d9da84a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categoricals'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategoricals\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/learn2env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_keywords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_deprecations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn2env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_handle_deprecations\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0msel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 \u001b[0msel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
     ]
    }
   ],
   "source": [
    "encoder = OneHotEncoder(categorical_features='categoricals', handle_unknown='ignore')\n",
    "encoder.fit(X_train[categoricals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-624cb1695d3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m X_train = pd.DataFrame(encoder.transform(X_train).toarray,\n\u001b[0m\u001b[1;32m      2\u001b[0m                          columns=encoder.get_feature_names())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = pd.DataFrame(encoder.transform(X_train).toarray,\n",
    "                         columns=encoder.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/humanperson/anaconda3/envs/learn2env/lib/python3.7/site-packages/numpy/lib/arraysetops.py:565: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n",
      "/Users/humanperson/anaconda3/envs/learn2env/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Closed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c7241219be1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m X_train = pd.DataFrame(encoder.transform(X_train).toarray(), index_col='Ticket_Id',\n\u001b[0m\u001b[1;32m      2\u001b[0m                          columns=encoder.get_feature_names())\n\u001b[1;32m      3\u001b[0m X_test = pd.DataFrame(encoder.transform(X_test).toarray(), index_col='Ticket_Id',\n\u001b[1;32m      4\u001b[0m                         columns=encoder.get_feature_names())\n",
      "\u001b[0;32m~/anaconda3/envs/learn2env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    730\u001b[0m                                        copy=True)\n\u001b[1;32m    731\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn2env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform_new\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;34m\"\"\"New implementation assuming categorical input\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;31m# validation of X happens in _check_X called by _transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0mX_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_int\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn2env/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, handle_unknown)\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mXi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0mXi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mvalid_mask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mX_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Closed'"
     ]
    }
   ],
   "source": [
    "X_train = pd.DataFrame(encoder.transform(X_train).toarray(), index_col='Ticket_Id',\n",
    "                         columns=encoder.get_feature_names())\n",
    "X_test = pd.DataFrame(encoder.transform(X_test).toarray(), index_col='Ticket_Id',\n",
    "                        columns=encoder.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '101_knn.pkl'\n",
    "pickle.dump(knn, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '101_lr.pkl'\n",
    "pickle.dump(lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state=42, min_samples_leaf=30)\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '101_gb.pkl'\n",
    "pickle.dump(gb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42, min_samples_leaf=30)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '101_dt.pkl'\n",
    "pickle.dump(dt, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = BaggingClassifier(random_state=25565)\n",
    "bg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '101_bg.pkl'\n",
    "pickle.dump(bg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '101_rf.pkl'\n",
    "pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a function to take in Ticket_Id and return root cause probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.loc[y_test.index == 13043]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(X_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_props = lr.predict_proba(X_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp = list(zip(lr.classes_, l_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want a dictionary that gives probability for each class, \n",
    "#prediction, and ground truth\n",
    "def display_preds_truth(model, Ticket_Id, X_test, y_test):\n",
    "    probs = model.predict_proba(X_test.loc[X_test.index == Ticket_Id])\n",
    "    classes = model.classes_\n",
    "    display = dict(zip(classes, probs))\n",
    "    display['prediction'] = model.predict(X_test.loc[X_test.index == Ticket_Id])\n",
    "    display['ground truth'] = y_test.loc[y_test.index == Ticket_Id]\n",
    "    return display\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_test[8541])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_test.loc[X_test.index == 8541])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_preds_truth(lr, 8541, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want a dictionary that gives probability for each class,\n",
    "def display_probas(model, obs, X_test):\n",
    "    probs = model.predict_proba(X_test)[obs]\n",
    "    classes = model.classes_\n",
    "    display = dict(zip(classes, probs))\n",
    "    display['prediction'] = model.predict(X_test)[obs]\n",
    "    return display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_probas(lr, 1, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn2env",
   "language": "python",
   "name": "learn2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
