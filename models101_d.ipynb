{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In which we used 'days ago' instead of datetimes so we can run more models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on features from Omnidian database 101, we compare K-Nearest Neighbors, Gradient Boosting, Random Forest, Bagging, and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from scipy import stats\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-paper')\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df101_d = pd.read_csv('data/eda101_d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 825 entries, 0 to 824\n",
      "Data columns (total 14 columns):\n",
      "ticket_id                   825 non-null int64\n",
      "asset_id                    825 non-null int64\n",
      "root_cause                  825 non-null object\n",
      "ticket_creation_reason      825 non-null object\n",
      "latitude                    825 non-null float64\n",
      "longitude                   825 non-null float64\n",
      "tilt                        825 non-null float64\n",
      "azimuth                     825 non-null float64\n",
      "ticket_origin               825 non-null object\n",
      "service_partner             825 non-null object\n",
      "ticket_assigned_days_ago    825 non-null int64\n",
      "ticket_closed_days_ago      825 non-null int64\n",
      "installed_by                825 non-null object\n",
      "installed_days_ago          825 non-null int64\n",
      "dtypes: float64(4), int64(5), object(5)\n",
      "memory usage: 90.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df101_d.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both ticket_id and asset_id need to be strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 825 entries, 0 to 824\n",
      "Data columns (total 14 columns):\n",
      "ticket_id                   825 non-null object\n",
      "asset_id                    825 non-null object\n",
      "root_cause                  825 non-null object\n",
      "ticket_creation_reason      825 non-null object\n",
      "latitude                    825 non-null float64\n",
      "longitude                   825 non-null float64\n",
      "tilt                        825 non-null float64\n",
      "azimuth                     825 non-null float64\n",
      "ticket_origin               825 non-null object\n",
      "service_partner             825 non-null object\n",
      "ticket_assigned_days_ago    825 non-null int64\n",
      "ticket_closed_days_ago      825 non-null int64\n",
      "installed_by                825 non-null object\n",
      "installed_days_ago          825 non-null int64\n",
      "dtypes: float64(4), int64(3), object(7)\n",
      "memory usage: 90.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df101_d[['ticket_id', 'asset_id']] = df101_d[['ticket_id', 'asset_id']].astype(object)\n",
    "df101_d.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign target to Root_Cause and Train-Test-Split. We'll also take the ticket_id off now so we can use it later to look rows up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df101_d.drop(['root_cause'], axis=1).copy()\n",
    "y = df101_d['root_cause'].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try some featureunionstuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PandasFeatureUnion(FeatureUnion):\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self._validate_transformers()\n",
    "        result = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_fit_transform_one)(trans, weight, X, y,\n",
    "                                        **fit_params)\n",
    "            for name, trans, weight in self._iter())\n",
    "\n",
    "        if not result:\n",
    "            # All transformers are None\n",
    "            return np.zeros((X.shape[0], 0))\n",
    "        Xs, transformers = zip(*result)\n",
    "        self._update_transformer_list(transformers)\n",
    "        if any(sparse.issparse(f) for f in Xs):\n",
    "            Xs = sparse.hstack(Xs).tocsr()\n",
    "        else:\n",
    "            Xs = self.merge_dataframes_by_column(Xs)\n",
    "        return Xs\n",
    "\n",
    "    def merge_dataframes_by_column(self, Xs):\n",
    "        return pd.concat(Xs, axis=\"columns\", copy=False)\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xs = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(_transform_one)(trans, weight, X)\n",
    "            for name, trans, weight in self._iter())\n",
    "        if not Xs:\n",
    "            # All transformers are None\n",
    "            return np.zeros((X.shape[0], 0))\n",
    "        if any(sparse.issparse(f) for f in Xs):\n",
    "            Xs = sparse.hstack(Xs).tocsr()\n",
    "        else:\n",
    "            Xs = self.merge_dataframes_by_column(Xs)\n",
    "        return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-74-dc24f6e36e1b>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-74-dc24f6e36e1b>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    pipeline.fit_transform(X_test)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pipeline = PandasFeatureUnion([\n",
    "    (\"C\", make_pipeline(\n",
    "        PandasTransform(OneHotEncoder(handle_unknown='ignore'), categoricals)\n",
    "    ))]\n",
    "    \n",
    "\n",
    "pipeline.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try ColumnTransformer. We'll pull ticket_id from the dataframes to keep them from being encoded, then we'll put them back together for our function later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ticket = X_train.ticket_id.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_sans_ticket = X_train.drop(['ticket_id'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ticket = X_test.ticket_id.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sans_ticket = X_test.drop(['ticket_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asset_id',\n",
       " 'ticket_creation_reason',\n",
       " 'ticket_origin',\n",
       " 'service_partner',\n",
       " 'installed_by']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List our categorical features\n",
    "categoricals = list(X_train.columns[(X_train.dtypes.values == np.dtype('object'))])\n",
    "categoricals.remove('ticket_id')\n",
    "categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude',\n",
       " 'longitude',\n",
       " 'tilt',\n",
       " 'azimuth',\n",
       " 'ticket_assigned_days_ago',\n",
       " 'ticket_closed_days_ago',\n",
       " 'installed_days_ago']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_nums = list(df101_d.columns[(df101_d.dtypes.values != np.dtype('object'))])\n",
    "X_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>tilt</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>ticket_assigned_days_ago</th>\n",
       "      <th>ticket_closed_days_ago</th>\n",
       "      <th>installed_days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>34.038597</td>\n",
       "      <td>-118.493806</td>\n",
       "      <td>40.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>310</td>\n",
       "      <td>229</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>39.923479</td>\n",
       "      <td>-74.751410</td>\n",
       "      <td>30.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>331</td>\n",
       "      <td>331</td>\n",
       "      <td>2407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>38.251630</td>\n",
       "      <td>-122.149367</td>\n",
       "      <td>23.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>531</td>\n",
       "      <td>486</td>\n",
       "      <td>1734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>34.448895</td>\n",
       "      <td>-119.260475</td>\n",
       "      <td>9.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>529</td>\n",
       "      <td>485</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>34.138321</td>\n",
       "      <td>-117.556590</td>\n",
       "      <td>23.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>439</td>\n",
       "      <td>379</td>\n",
       "      <td>1607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude   longitude  tilt  azimuth  ticket_assigned_days_ago  \\\n",
       "239  34.038597 -118.493806  40.0    225.0                       310   \n",
       "689  39.923479  -74.751410  30.0    160.0                       331   \n",
       "644  38.251630 -122.149367  23.0    152.0                       531   \n",
       "342  34.448895 -119.260475   9.0    180.0                       529   \n",
       "299  34.138321 -117.556590  23.0    180.0                       439   \n",
       "\n",
       "     ticket_closed_days_ago  installed_days_ago  \n",
       "239                     229                1929  \n",
       "689                     331                2407  \n",
       "644                     486                1734  \n",
       "342                     485                1965  \n",
       "299                     379                1607  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num = X_train[X_nums].copy()\n",
    "X_train_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 660 entries, 239 to 102\n",
      "Data columns (total 7 columns):\n",
      "latitude                    660 non-null float64\n",
      "longitude                   660 non-null float64\n",
      "tilt                        660 non-null float64\n",
      "azimuth                     660 non-null float64\n",
      "ticket_assigned_days_ago    660 non-null int64\n",
      "ticket_closed_days_ago      660 non-null int64\n",
      "installed_days_ago          660 non-null int64\n",
      "dtypes: float64(4), int64(3)\n",
      "memory usage: 41.2 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>tilt</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>ticket_assigned_days_ago</th>\n",
       "      <th>ticket_closed_days_ago</th>\n",
       "      <th>installed_days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>37.818595</td>\n",
       "      <td>-121.934280</td>\n",
       "      <td>23.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>390</td>\n",
       "      <td>324</td>\n",
       "      <td>2704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>33.840872</td>\n",
       "      <td>-111.771766</td>\n",
       "      <td>34.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>702</td>\n",
       "      <td>325</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>40.768241</td>\n",
       "      <td>-74.510319</td>\n",
       "      <td>18.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>479</td>\n",
       "      <td>395</td>\n",
       "      <td>2113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>33.866658</td>\n",
       "      <td>-118.387667</td>\n",
       "      <td>23.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>377</td>\n",
       "      <td>346</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>34.314705</td>\n",
       "      <td>-118.432859</td>\n",
       "      <td>23.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>461</td>\n",
       "      <td>387</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      latitude   longitude  tilt  azimuth  ticket_assigned_days_ago  \\\n",
       "611  37.818595 -121.934280  23.0    170.0                       390   \n",
       "174  33.840872 -111.771766  34.0    232.0                       702   \n",
       "67   40.768241  -74.510319  18.0    224.0                       479   \n",
       "168  33.866658 -118.387667  23.0     55.0                       377   \n",
       "275  34.314705 -118.432859  23.0    132.0                       461   \n",
       "\n",
       "     ticket_closed_days_ago  installed_days_ago  \n",
       "611                     324                2704  \n",
       "174                     325                1529  \n",
       "67                      395                2113  \n",
       "168                     346                1335  \n",
       "275                     387                1420  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_num = X_test[X_nums].copy()\n",
    "X_test_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 165 entries, 611 to 527\n",
      "Data columns (total 7 columns):\n",
      "latitude                    165 non-null float64\n",
      "longitude                   165 non-null float64\n",
      "tilt                        165 non-null float64\n",
      "azimuth                     165 non-null float64\n",
      "ticket_assigned_days_ago    165 non-null int64\n",
      "ticket_closed_days_ago      165 non-null int64\n",
      "installed_days_ago          165 non-null int64\n",
      "dtypes: float64(4), int64(3)\n",
      "memory usage: 10.3 KB\n"
     ]
    }
   ],
   "source": [
    "X_test_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer( (OneHotEncoder(handle_unknown='ignore'), categoricals))\n",
    "encoder = preprocessor.fit(X_train_sans_ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_enc = pd.DataFrame(encoder.transform(X_train).toarray(),\n",
    "                         columns=encoder.get_feature_names())\n",
    "X_test_enc = pd.DataFrame(encoder.transform(X_test).toarray(),\n",
    "                        columns=encoder.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onehotencoder__x0_101111473</th>\n",
       "      <th>onehotencoder__x0_101111478</th>\n",
       "      <th>onehotencoder__x0_101111489</th>\n",
       "      <th>onehotencoder__x0_101111511</th>\n",
       "      <th>onehotencoder__x0_101111521</th>\n",
       "      <th>onehotencoder__x0_101111528</th>\n",
       "      <th>onehotencoder__x0_101111533</th>\n",
       "      <th>onehotencoder__x0_101111565</th>\n",
       "      <th>onehotencoder__x0_101111567</th>\n",
       "      <th>onehotencoder__x0_101111573</th>\n",
       "      <th>...</th>\n",
       "      <th>onehotencoder__x4_solar alliance of america inc.</th>\n",
       "      <th>onehotencoder__x4_solar energy world nj</th>\n",
       "      <th>onehotencoder__x4_solar plus llc</th>\n",
       "      <th>onehotencoder__x4_sonic solar energy</th>\n",
       "      <th>onehotencoder__x4_summerwindsolar llc phoenix</th>\n",
       "      <th>onehotencoder__x4_summit technology group</th>\n",
       "      <th>onehotencoder__x4_sunstarter solar installations inc</th>\n",
       "      <th>onehotencoder__x4_syntrol plumbing heating and air</th>\n",
       "      <th>onehotencoder__x4_talbott solar home</th>\n",
       "      <th>onehotencoder__x4_williams lifetime builders inc. dba lifetime solar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   onehotencoder__x0_101111473  onehotencoder__x0_101111478  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   onehotencoder__x0_101111489  onehotencoder__x0_101111511  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   onehotencoder__x0_101111521  onehotencoder__x0_101111528  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   onehotencoder__x0_101111533  onehotencoder__x0_101111565  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   onehotencoder__x0_101111567  onehotencoder__x0_101111573  ...  \\\n",
       "0                          0.0                          0.0  ...   \n",
       "1                          0.0                          0.0  ...   \n",
       "2                          0.0                          0.0  ...   \n",
       "3                          0.0                          0.0  ...   \n",
       "4                          0.0                          0.0  ...   \n",
       "\n",
       "   onehotencoder__x4_solar alliance of america inc.  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "\n",
       "   onehotencoder__x4_solar energy world nj  onehotencoder__x4_solar plus llc  \\\n",
       "0                                      0.0                               0.0   \n",
       "1                                      1.0                               0.0   \n",
       "2                                      0.0                               0.0   \n",
       "3                                      0.0                               0.0   \n",
       "4                                      0.0                               0.0   \n",
       "\n",
       "   onehotencoder__x4_sonic solar energy  \\\n",
       "0                                   0.0   \n",
       "1                                   0.0   \n",
       "2                                   0.0   \n",
       "3                                   0.0   \n",
       "4                                   0.0   \n",
       "\n",
       "   onehotencoder__x4_summerwindsolar llc phoenix  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "\n",
       "   onehotencoder__x4_summit technology group  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   onehotencoder__x4_sunstarter solar installations inc  \\\n",
       "0                                                0.0      \n",
       "1                                                0.0      \n",
       "2                                                0.0      \n",
       "3                                                0.0      \n",
       "4                                                0.0      \n",
       "\n",
       "   onehotencoder__x4_syntrol plumbing heating and air  \\\n",
       "0                                                0.0    \n",
       "1                                                0.0    \n",
       "2                                                1.0    \n",
       "3                                                0.0    \n",
       "4                                                0.0    \n",
       "\n",
       "   onehotencoder__x4_talbott solar home  \\\n",
       "0                                   0.0   \n",
       "1                                   0.0   \n",
       "2                                   0.0   \n",
       "3                                   0.0   \n",
       "4                                   0.0   \n",
       "\n",
       "   onehotencoder__x4_williams lifetime builders inc. dba lifetime solar  \n",
       "0                                                0.0                     \n",
       "1                                                0.0                     \n",
       "2                                                0.0                     \n",
       "3                                                0.0                     \n",
       "4                                                0.0                     \n",
       "\n",
       "[5 rows x 389 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 660 entries, 0 to 659\n",
      "Columns: 389 entries, onehotencoder__x0_101111473 to onehotencoder__x4_williams lifetime builders inc. dba lifetime solar\n",
      "dtypes: float64(389)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "X_train_enc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ticket.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll put the ticket_id, numerical columns, and encoded columns all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>tilt</th>\n",
       "      <th>azimuth</th>\n",
       "      <th>ticket_assigned_days_ago</th>\n",
       "      <th>ticket_closed_days_ago</th>\n",
       "      <th>installed_days_ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>20902</td>\n",
       "      <td>34.038597</td>\n",
       "      <td>-118.493806</td>\n",
       "      <td>40.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>310</td>\n",
       "      <td>229</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>19046</td>\n",
       "      <td>39.923479</td>\n",
       "      <td>-74.751410</td>\n",
       "      <td>30.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>331</td>\n",
       "      <td>331</td>\n",
       "      <td>2407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>8381</td>\n",
       "      <td>38.251630</td>\n",
       "      <td>-122.149367</td>\n",
       "      <td>23.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>531</td>\n",
       "      <td>486</td>\n",
       "      <td>1734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>8324</td>\n",
       "      <td>34.448895</td>\n",
       "      <td>-119.260475</td>\n",
       "      <td>9.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>529</td>\n",
       "      <td>485</td>\n",
       "      <td>1965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>13319</td>\n",
       "      <td>34.138321</td>\n",
       "      <td>-117.556590</td>\n",
       "      <td>23.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>439</td>\n",
       "      <td>379</td>\n",
       "      <td>1607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticket_id   latitude   longitude  tilt  azimuth  ticket_assigned_days_ago  \\\n",
       "239     20902  34.038597 -118.493806  40.0    225.0                       310   \n",
       "689     19046  39.923479  -74.751410  30.0    160.0                       331   \n",
       "644      8381  38.251630 -122.149367  23.0    152.0                       531   \n",
       "342      8324  34.448895 -119.260475   9.0    180.0                       529   \n",
       "299     13319  34.138321 -117.556590  23.0    180.0                       439   \n",
       "\n",
       "     ticket_closed_days_ago  installed_days_ago  \n",
       "239                     229                1929  \n",
       "689                     331                2407  \n",
       "644                     486                1734  \n",
       "342                     485                1965  \n",
       "299                     379                1607  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_num.insert(loc=0, column='ticket_id', value=train_ticket)\n",
    "X_train_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 660 entries, 239 to 102\n",
      "Data columns (total 8 columns):\n",
      "ticket_id                   660 non-null object\n",
      "latitude                    660 non-null float64\n",
      "longitude                   660 non-null float64\n",
      "tilt                        660 non-null float64\n",
      "azimuth                     660 non-null float64\n",
      "ticket_assigned_days_ago    660 non-null int64\n",
      "ticket_closed_days_ago      660 non-null int64\n",
      "installed_days_ago          660 non-null int64\n",
      "dtypes: float64(4), int64(3), object(1)\n",
      "memory usage: 46.4+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train_num.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Must pass right_on or right_index=True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-b4170c629e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_mega\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/learn2env/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     45\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn2env/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUserWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_specification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;31m# note this function has side effects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/learn2env/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_validate_specification\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_on\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mMergeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Must pass right_on or right_index=True'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_on\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMergeError\u001b[0m: Must pass right_on or right_index=True"
     ]
    }
   ],
   "source": [
    "X_train_mega = pd.merge(X_train_num, X_train_enc, left_index=True, right_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mega.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_mega = pd.concat([X_train_num, X_train_enc], axis=1, join_axes=[X_train_enc.index])\n",
    "X_train_mega.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mega.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mega.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num.insert(loc=0, column='ticket_id', value=test_ticket)\n",
    "X_test_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mega = pd.concat([X_test_num, X_test_enc], axis=1, join_axes=[X_test_num.index])\n",
    "X_test_mega.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_mega.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_train_mega, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval_model(Classifier, X_train, y_train, X_test, y_test):\n",
    "    Classifier.fit(X_train, y_train)\n",
    "    return Classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_eval_model(BernoulliNB(alpha=.01), X_train_mega, y_train, X_test_mega, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state=42, min_samples_leaf=30)\n",
    "gb.fit(X_train_mega, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.score(X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '101_knn.pkl'\n",
    "# pickle.dump(knn, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kn = pickle.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '101_lr.pkl'\n",
    "# pickle.dump(lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(random_state=42, min_samples_leaf=30)\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '101_gb.pkl'\n",
    "# pickle.dump(gb, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(random_state=42, min_samples_leaf=30)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '101_dt.pkl'\n",
    "# pickle.dump(dt, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = BaggingClassifier(random_state=25565)\n",
    "bg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '101_bg.pkl'\n",
    "# pickle.dump(bg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '101_rf.pkl'\n",
    "# pickle.dump(rf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What may be some other classifiers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.testing import all_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict_proba(X_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(X_test)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_props = lr.predict_proba(X_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipp = list(zip(lr.classes_, l_props))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want a dictionary that gives probability for each class, \n",
    "#prediction, and ground truth\n",
    "def display_preds_truth(model, obs, X_test, y_test):\n",
    "    probs = model.predict_proba(X_test)[obs]\n",
    "    classes = model.classes_\n",
    "    display = dict(zip(classes, probs))\n",
    "#     display['prediction'] = model.predict(X_test)[obs]\n",
    "    display['ground truth'] = y_test[obs]\n",
    "    return display\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#want a dictionary that gives probability for each class,\n",
    "def display_probas(model, obs, X_test):\n",
    "    probs = model.predict_proba(X_test)[obs]\n",
    "    classes = model.classes_\n",
    "    display = dict(zip(classes, probs))\n",
    "    display['prediction'] = model.predict(X_test)[obs]\n",
    "    return display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_probas(lr, 1, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn2env",
   "language": "python",
   "name": "learn2env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
